{
  "recentFiles": [
    {
      "basename": "datav--Tasks",
      "path": "datav--Tasks.md"
    },
    {
      "basename": "LAB",
      "path": "LAB.md"
    },
    {
      "basename": "🔗NTNU",
      "path": "NTNU/Org/🔗NTNU.md"
    },
    {
      "basename": "Write my RL theory questions and send to Ole and Bjarne",
      "path": "P-Tasks/➕/Write my RL theory questions and send to Ole and Bjarne.md"
    },
    {
      "basename": "datav--Tasks--organizing--has-deadline",
      "path": "datav--Tasks--organizing--has-deadline.md"
    },
    {
      "basename": "reimburcement of December 2022 Stavanger trip",
      "path": "P-Tasks/➕/reimburcement of December 2022 Stavanger trip.md"
    },
    {
      "basename": "🧑🏨NTNU Hjelp",
      "path": "NTNU/Org/🧑People/🧑🏨NTNU Hjelp.md"
    },
    {
      "basename": "🔲5",
      "path": "🔲5.md"
    },
    {
      "basename": "Reinforcement Learning Map",
      "path": "Literature/Theory/Reinforcement Learning/Reinforcement Learning Map.canvas"
    },
    {
      "basename": "value-functions-approximation",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/value-functions-approximation.md"
    },
    {
      "basename": "⚠ Vanishing Gradient problem",
      "path": "Literature/Notes/⚠ Warnings/Implementations/⚠ Vanishing Gradient problem.md"
    },
    {
      "basename": "💭 Against--RL--Monte-Carlo",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--RL--Monte-Carlo.md"
    },
    {
      "basename": "eq--P_hat--play",
      "path": "Literature/Notes/Equations/eq--P_hat--play.md"
    },
    {
      "basename": "eq--Sylvester-Equation",
      "path": "Literature/Notes/Equations/eq--Sylvester-Equation.md"
    },
    {
      "basename": "eq--proof-ratio-1",
      "path": "Literature/Notes/Equations/eq--proof-ratio-1.pdf"
    },
    {
      "basename": "☹ disadvantages",
      "path": "P-Tasks/➕/👨🏼‍🎓/🧪/☹ disadvantages.md"
    },
    {
      "basename": "datav--Pubs-all",
      "path": "Literature/datav--Pubs-all.md"
    },
    {
      "basename": "⚠ Potential change of offices",
      "path": "P-Tasks/➕/⚠ Potential change of offices.md"
    },
    {
      "basename": "🧑Berit-Dahl",
      "path": "NTNU/Org/🧑People/🧑Berit-Dahl.md"
    },
    {
      "basename": "⚠ Seek advice on dealing with lack of respect",
      "path": "P-Tasks/➕/⚠ Seek advice on dealing with lack of respect.md"
    },
    {
      "basename": "p372--monte carlo has high variance",
      "path": "Literature/Notes/p372--monte carlo has high variance.md"
    },
    {
      "basename": "➕❓why-is-that--bias-in-TD-learning",
      "path": "Literature/Notes/➕❓why-is-that--bias-in-TD-learning.md"
    },
    {
      "basename": "🧑Ole-Morten",
      "path": "NTNU/Org/🧑People/🧑Ole-Morten.md"
    },
    {
      "basename": "⚠️⚠️⚠️ Wait for refund from EECI for transaction mistake",
      "path": "P-Tasks/➕/⚠️⚠️⚠️ Wait for refund from EECI for transaction mistake.md"
    },
    {
      "basename": "🧑🏨EECI",
      "path": "NTNU/Org/🧑People/🧑🏨EECI.md"
    },
    {
      "basename": "datav--Pubs",
      "path": "Literature/datav--Pubs.md"
    },
    {
      "basename": "check if eligible for Sit-exam for Adaptive Control",
      "path": "P-Tasks/✔/check if eligible for Sit-exam for Adaptive Control.md"
    },
    {
      "basename": "ORG -- DISTRIBUTED CONTROL COURSE",
      "path": "P-Tasks/✔/ORG -- DISTRIBUTED CONTROL COURSE.md"
    },
    {
      "basename": "📁🔗",
      "path": "Automations/📁🔗.md"
    },
    {
      "basename": "➕📧--Quick",
      "path": "Automations/➕📧--Quick.md"
    },
    {
      "basename": "p220--On policy VS off policy",
      "path": "Literature/Notes/p220--On policy VS off policy.md"
    },
    {
      "basename": "has--logic",
      "path": "Literature/Properties/in math/has--logic.md"
    },
    {
      "basename": "booking flights and Hotel to Paris",
      "path": "P-Tasks/➕/booking flights and Hotel to Paris.md"
    },
    {
      "basename": "Computational benefit of Temporal Difference Learning",
      "path": "Literature/Notes/Computational benefit of Temporal Difference Learning.md"
    },
    {
      "basename": "EDUCATIONAL",
      "path": "P-Tasks/➕/ALL/EDUCATIONAL.md"
    },
    {
      "basename": "check-questions-noted-while-reading",
      "path": "P-Tasks/➕/👨🏼‍🎓/check-questions-noted-while-reading.md"
    },
    {
      "basename": "💭 Against--RL--expected-updates",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--RL--expected-updates.md"
    },
    {
      "basename": "eq--expected update for state-action pair",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/update equations/eq--expected update for state-action pair.md"
    },
    {
      "basename": "sampling error",
      "path": "Literature/Notes/sampling error.md"
    },
    {
      "basename": "p379--1",
      "path": "Literature/Notes/p379--1.md"
    },
    {
      "basename": "p220--37",
      "path": "Literature/Notes/p220--37.md"
    },
    {
      "basename": "environment-dynamics",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/environment-dynamics.md"
    },
    {
      "basename": "MONTE CARLO METHODS",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/MONTE CARLO METHODS.md"
    },
    {
      "basename": "p220",
      "path": "Literature/Notes/p220.md"
    },
    {
      "basename": "p220--non learnable quantities in Reinforcement Learning Exist",
      "path": "Literature/Notes/p220--non learnable quantities in Reinforcement Learning Exist.md"
    },
    {
      "basename": "p220--how to achieve unbiased expectation sampling",
      "path": "Literature/Notes/p220--how to achieve unbiased expectation sampling.md"
    },
    {
      "basename": "p220--89",
      "path": "Literature/Notes/p220--89.md"
    },
    {
      "basename": "Stochastic-gradient-descent SGD",
      "path": "Literature/Theory/Theory/Stochastic-gradient-descent SGD.md"
    },
    {
      "basename": "eq--RL--Residual-Gradient-Algorithm-update",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--RL--Residual-Gradient-Algorithm-update.md"
    },
    {
      "basename": "eq--Mean-Square-TD-Error",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--Mean-Square-TD-Error.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}