{
  "recentFiles": [
    {
      "basename": "p220",
      "path": "Literature/Notes/p220.md"
    },
    {
      "basename": "⚠🤷‍♂️1",
      "path": "Literature/Notes/💭 Arguments/mismatches with my understanding-opinion/⚠🤷‍♂️1.md"
    },
    {
      "basename": "datav--Tasks",
      "path": "datav--Tasks.md"
    },
    {
      "basename": "PAY FOR DISTRIBUTED CONTROL COURSE",
      "path": "P-Tasks/✔/PAY FOR DISTRIBUTED CONTROL COURSE.md"
    },
    {
      "basename": "p379--1",
      "path": "Literature/Notes/p379--1.md"
    },
    {
      "basename": "datav--Pubs",
      "path": "Literature/datav--Pubs.md"
    },
    {
      "basename": "write about experience",
      "path": "P-Tasks/✔/write about experience.md"
    },
    {
      "basename": "👨‍🎓--adaptive-control",
      "path": "P-Tasks/➕/👨🏼‍🎓/👨‍🎓--adaptive-control.md"
    },
    {
      "basename": "➡ download and read citation",
      "path": "P-Tasks/➕/➡ download and read citation.md"
    },
    {
      "basename": "➕🔎 check more trustworthy source",
      "path": "P-Tasks/➕/Untitled/➕🔎 check more trustworthy source.md"
    },
    {
      "basename": "➕🔎 continue internet search",
      "path": "P-Tasks/➕/Untitled/➕🔎 continue internet search.md"
    },
    {
      "basename": "LAB",
      "path": "LAB.md"
    },
    {
      "basename": "p220--how to achieve unbiased expectation sampling",
      "path": "Literature/Notes/p220--how to achieve unbiased expectation sampling.md"
    },
    {
      "basename": "has--logic",
      "path": "Literature/Properties/in math/has--logic.md"
    },
    {
      "basename": "p220--89",
      "path": "Literature/Notes/p220--89.md"
    },
    {
      "basename": "Stochastic-gradient-descent SGD",
      "path": "Literature/Theory/Theory/Stochastic-gradient-descent SGD.md"
    },
    {
      "basename": "eq--RL--Residual-Gradient-Algorithm-update",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--RL--Residual-Gradient-Algorithm-update.md"
    },
    {
      "basename": "eq--Mean-Square-TD-Error",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--Mean-Square-TD-Error.md"
    },
    {
      "basename": "p379",
      "path": "Literature/Notes/p379.md"
    },
    {
      "basename": "Reinforcement learning--Self-study-report",
      "path": "P-Tasks/➕/👨‍🎓/Reinforcement learning--Self-study-report.md"
    },
    {
      "basename": "p220--stochastic gradient descent",
      "path": "Literature/Notes/p220--stochastic gradient descent.md"
    },
    {
      "basename": "p220--90",
      "path": "Literature/Notes/p220--90.md"
    },
    {
      "basename": "p220--On policy VS off policy",
      "path": "Literature/Notes/p220--On policy VS off policy.md"
    },
    {
      "basename": "🧪--PhD-NTNU--Self-Study--Reinforcement-Learning--Pub-Reading",
      "path": "NTNU/Org/🧪Projects/🧪--PhD-NTNU--Self-Study--Reinforcement-Learning--Pub-Reading.md"
    },
    {
      "basename": "Why--are those convergence properties like this",
      "path": "P-Tasks/➕/👨‍🎓/Why--are those convergence properties like this.md"
    },
    {
      "basename": "💭 Against--RL--ε-greedy",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--RL--ε-greedy.md"
    },
    {
      "basename": "has--intuition",
      "path": "Literature/Properties/in Pubs/has--intuition.md"
    },
    {
      "basename": "p220--75",
      "path": "Literature/Notes/p220--75.md"
    },
    {
      "basename": "🧑Kristian-Lovland",
      "path": "NTNU/Org/🧑People/🧑Kristian-Lovland.md"
    },
    {
      "basename": "Computational benefit of Temporal Difference Learning",
      "path": "Literature/Notes/Computational benefit of Temporal Difference Learning.md"
    },
    {
      "basename": "p220--backprop no work for deeper nns",
      "path": "Literature/Notes/p220--backprop no work for deeper nns.md"
    },
    {
      "basename": "p220--28",
      "path": "Literature/Notes/p220--28.md"
    },
    {
      "basename": "p220--⚠Modeling error danger",
      "path": "Literature/Notes/p220--⚠Modeling error danger.md"
    },
    {
      "basename": "p371",
      "path": "Literature/Notes/p371.md"
    },
    {
      "basename": "p372",
      "path": "Literature/Notes/p372.md"
    },
    {
      "basename": "p373",
      "path": "Literature/Notes/p373.md"
    },
    {
      "basename": "p374",
      "path": "Literature/Notes/p374.md"
    },
    {
      "basename": "p375",
      "path": "Literature/Notes/p375.md"
    },
    {
      "basename": "p376",
      "path": "Literature/Notes/p376.md"
    },
    {
      "basename": "p377",
      "path": "Literature/Notes/p377.md"
    },
    {
      "basename": "p378",
      "path": "Literature/Notes/p378.md"
    },
    {
      "basename": "p379--curse of dimensionality",
      "path": "Literature/Notes/p379--curse of dimensionality.md"
    },
    {
      "basename": "p376--2",
      "path": "Literature/Notes/p376--2.md"
    },
    {
      "basename": "CMD__GET_PUB",
      "path": "CMD__GET_PUB.md"
    },
    {
      "basename": "p375--3",
      "path": "Literature/Notes/p375--3.md"
    },
    {
      "basename": "p375--Semi-gradient-methods-lack-theoretical-support---2020",
      "path": "Literature/Notes/p375--Semi-gradient-methods-lack-theoretical-support---2020.md"
    },
    {
      "basename": "p371--suboptimal policies",
      "path": "Literature/Notes/p371--suboptimal policies.md"
    },
    {
      "basename": "p372--monte carlo has high variance",
      "path": "Literature/Notes/p372--monte carlo has high variance.md"
    },
    {
      "basename": "➕❓why-is-that--bias-in-TD-learning",
      "path": "Literature/Notes/➕❓why-is-that--bias-in-TD-learning.md"
    },
    {
      "basename": "🧑Ole-Morten",
      "path": "NTNU/Org/🧑People/🧑Ole-Morten.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}