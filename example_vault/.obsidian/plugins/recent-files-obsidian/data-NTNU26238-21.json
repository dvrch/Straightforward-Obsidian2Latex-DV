{
  "recentFiles": [
    {
      "basename": "ğŸ—£--rolling-of-Sleeves-on-Wellborne",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/ğŸ—£--rolling-of-Sleeves-on-Wellborne.md"
    },
    {
      "basename": "ğŸ§‘Adrian-Ambrus--DigiWells",
      "path": "NTNU/Org/ğŸ§‘People/ğŸ§‘Adrian-Ambrus--DigiWells.md"
    },
    {
      "basename": "ğŸ—£-quote-suggestion-idea--Ole",
      "path": "Automations/ğŸ—£-quote-suggestion-idea--Ole.md"
    },
    {
      "basename": "ğŸ—£--Damping-achieved-depends-on-other-states",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/ğŸ—£--Damping-achieved-depends-on-other-states.md"
    },
    {
      "basename": "ğŸ—£-omega_SP might not be available",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/ğŸ—£-omega_SP might not be available.md"
    },
    {
      "basename": "ğŸ—£Sleeve movementâ“",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/ğŸ—£Sleeve movementâ“.md"
    },
    {
      "basename": "has--â“unresolved-question-for-DigiWells-Sleeve-Slip",
      "path": "NTNU/Org/ğŸ§ªProjects/Sleeve-Slip--DigiWells/has--â“unresolved-question-for-DigiWells-Sleeve-Slip.md"
    },
    {
      "basename": "â•--DigiWells--UNRESOLVED-QUESTIONS",
      "path": "P-Tasks/â•/â•--DigiWells--UNRESOLVED-QUESTIONS.md"
    },
    {
      "basename": "datav--tasks--DigiWells--Sleeve-Slip",
      "path": "datav--tasks--DigiWells--Sleeve-Slip.md"
    },
    {
      "basename": "datav--Tasks",
      "path": "datav--Tasks.md"
    },
    {
      "basename": "DigiWells--Sleeves--MATLAB-Code",
      "path": "NTNU/Org/ğŸ§ªProjects/Sleeve-Slip--DigiWells/DigiWells--Sleeves--MATLAB-Code.md"
    },
    {
      "basename": "eq--P-off-controller",
      "path": "NTNU/Org/ğŸ§ªProjects/Sleeve-Slip--DigiWells/Equations/eq--P-off-controller.md"
    },
    {
      "basename": "â•Apply Ole's suggestions for ppt",
      "path": "P-Tasks/â•/â•Apply Ole's suggestions for ppt.md"
    },
    {
      "basename": "eq--resulting-sleeve-damping-force--P-off-controller",
      "path": "NTNU/Org/ğŸ§ªProjects/Sleeve-Slip--DigiWells/Equations/eq--resulting-sleeve-damping-force--P-off-controller.md"
    },
    {
      "basename": "ğŸ—£-quote-suggestion-idea",
      "path": "Automations/ğŸ—£-quote-suggestion-idea.md"
    },
    {
      "basename": "PREP--Ole--Remind-that-I-Need-define-PhD",
      "path": "P-Tasks/â•/PREP--Ole--Remind-that-I-Need-define-PhD.md"
    },
    {
      "basename": "â•--Check-tasks-from-Ole-in-Supernote and move to Obsidian",
      "path": "P-Tasks/â•/â•--Check-tasks-from-Ole-in-Supernote and move to Obsidian.md"
    },
    {
      "basename": "ğŸ§ª--PhD-NTNU--Projects--Sleeve-Slip-Problem",
      "path": "NTNU/Org/ğŸ§ªProjects/Sleeve-Slip--DigiWells/ğŸ§ª--PhD-NTNU--Projects--Sleeve-Slip-Problem.md"
    },
    {
      "basename": "p477",
      "path": "Literature/Notes/p477.md"
    },
    {
      "basename": "ğŸ¨Deep-Mind",
      "path": "NTNU/Org/ğŸ§‘People/ğŸ¨Deep-Mind.md"
    },
    {
      "basename": "LAB",
      "path": "LAB.md"
    },
    {
      "basename": "â•make list of potential places for residency and visualize self",
      "path": "P-Tasks/â•/ğŸ‘¨â€ğŸ“/ğŸ§ª/â•make list of potential places for residency and visualize self.md"
    },
    {
      "basename": "ğŸ¨Uni--Melbourne",
      "path": "NTNU/Org/ğŸ§‘People/ğŸ¨Uni--Melbourne.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Stochastic-Gradient-Descent",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Stochastic-Gradient-Descent.md"
    },
    {
      "basename": "ğŸ”—--ppt--Meetings",
      "path": "Meetings/ğŸ”—--ppt--Meetings.md"
    },
    {
      "basename": "Visualize Science Course â“",
      "path": "P-Tasks/âœ”/Visualize Science Course â“.md"
    },
    {
      "basename": "Contents--datav-tasks",
      "path": "Contents--datav-tasks.md"
    },
    {
      "basename": "p451",
      "path": "Literature/Notes/p451.md"
    },
    {
      "basename": "eq--RL--Vanilla-policy-gradient-expression-with-advantage-function",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--RL--Vanilla-policy-gradient-expression-with-advantage-function.md"
    },
    {
      "basename": "p220--SGD update with linear function approximation",
      "path": "Literature/Notes/p220--SGD update with linear function approximation.md"
    },
    {
      "basename": "p220--89",
      "path": "Literature/Notes/p220--89.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--sigmoid--functions",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--sigmoid--functions.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--TRPO",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--TRPO.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Tile-Coding",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Tile-Coding.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Temporal-Difference-Learning",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Temporal-Difference-Learning.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Residual-Algorithms",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Residual-Algorithms.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Residual-Gradients",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Residual-Gradients.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--Policy-Gradient 2023-04-23 14_41_10",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--Policy-Gradient 2023-04-23 14_41_10.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--Reinforcement-Learning",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--Reinforcement-Learning.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--RL--approximating-value-functions",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--RL--approximating-value-functions.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--Integral-Adaptive-Law--against-Instantaneous-Adaptive-Law",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--Integral-Adaptive-Law--against-Instantaneous-Adaptive-Law.md"
    },
    {
      "basename": "ğŸ’­ In-favor-of--Iterative-Learning--Control",
      "path": "Literature/Notes/ğŸ’­ Arguments/in favor of/ğŸ’­ In-favor-of--Iterative-Learning--Control.md"
    },
    {
      "basename": "ğŸ’­ Against--Extremum-Seeking--Perturbation-Based",
      "path": "Literature/Notes/ğŸ’­ Arguments/against/ğŸ’­ Against--Extremum-Seeking--Perturbation-Based.md"
    },
    {
      "basename": "ğŸ’­ Against--high-frequency-perturbations",
      "path": "Literature/Notes/ğŸ’­ Arguments/against/ğŸ’­ Against--high-frequency-perturbations.md"
    },
    {
      "basename": "ğŸ’­ Against--Extremum-Seeking--Model-Based",
      "path": "Literature/Notes/ğŸ’­ Arguments/against/ğŸ’­ Against--Extremum-Seeking--Model-Based.md"
    },
    {
      "basename": "ğŸ’­ Against--Extremum--Seeking",
      "path": "Literature/Notes/ğŸ’­ Arguments/against/ğŸ’­ Against--Extremum--Seeking.md"
    },
    {
      "basename": "ğŸ’­ Against--Adaptive-Control-Approaches",
      "path": "Literature/Notes/ğŸ’­ Arguments/against/ğŸ’­ Against--Adaptive-Control-Approaches.md"
    },
    {
      "basename": "p220--63",
      "path": "Literature/Notes/p220--63.md"
    },
    {
      "basename": "hour-count--tasks",
      "path": "hour-count--tasks.md"
    },
    {
      "basename": "reimburcement of December 2022 Stavanger trip",
      "path": "P-Tasks/âœ”/reimburcement of December 2022 Stavanger trip.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}