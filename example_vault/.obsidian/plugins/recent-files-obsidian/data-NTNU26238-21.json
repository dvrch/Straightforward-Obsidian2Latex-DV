{
  "recentFiles": [
    {
      "basename": "🗣--rolling-of-Sleeves-on-Wellborne",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/🗣--rolling-of-Sleeves-on-Wellborne.md"
    },
    {
      "basename": "🧑Adrian-Ambrus--DigiWells",
      "path": "NTNU/Org/🧑People/🧑Adrian-Ambrus--DigiWells.md"
    },
    {
      "basename": "🗣-quote-suggestion-idea--Ole",
      "path": "Automations/🗣-quote-suggestion-idea--Ole.md"
    },
    {
      "basename": "🗣--Damping-achieved-depends-on-other-states",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/🗣--Damping-achieved-depends-on-other-states.md"
    },
    {
      "basename": "🗣-omega_SP might not be available",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/🗣-omega_SP might not be available.md"
    },
    {
      "basename": "🗣Sleeve movement❓",
      "path": "Meetings/Conversations/Quotes-suggestions-ideas/🗣Sleeve movement❓.md"
    },
    {
      "basename": "has--❓unresolved-question-for-DigiWells-Sleeve-Slip",
      "path": "NTNU/Org/🧪Projects/Sleeve-Slip--DigiWells/has--❓unresolved-question-for-DigiWells-Sleeve-Slip.md"
    },
    {
      "basename": "➕--DigiWells--UNRESOLVED-QUESTIONS",
      "path": "P-Tasks/➕/➕--DigiWells--UNRESOLVED-QUESTIONS.md"
    },
    {
      "basename": "datav--tasks--DigiWells--Sleeve-Slip",
      "path": "datav--tasks--DigiWells--Sleeve-Slip.md"
    },
    {
      "basename": "datav--Tasks",
      "path": "datav--Tasks.md"
    },
    {
      "basename": "DigiWells--Sleeves--MATLAB-Code",
      "path": "NTNU/Org/🧪Projects/Sleeve-Slip--DigiWells/DigiWells--Sleeves--MATLAB-Code.md"
    },
    {
      "basename": "eq--P-off-controller",
      "path": "NTNU/Org/🧪Projects/Sleeve-Slip--DigiWells/Equations/eq--P-off-controller.md"
    },
    {
      "basename": "➕Apply Ole's suggestions for ppt",
      "path": "P-Tasks/➕/➕Apply Ole's suggestions for ppt.md"
    },
    {
      "basename": "eq--resulting-sleeve-damping-force--P-off-controller",
      "path": "NTNU/Org/🧪Projects/Sleeve-Slip--DigiWells/Equations/eq--resulting-sleeve-damping-force--P-off-controller.md"
    },
    {
      "basename": "🗣-quote-suggestion-idea",
      "path": "Automations/🗣-quote-suggestion-idea.md"
    },
    {
      "basename": "PREP--Ole--Remind-that-I-Need-define-PhD",
      "path": "P-Tasks/➕/PREP--Ole--Remind-that-I-Need-define-PhD.md"
    },
    {
      "basename": "➕--Check-tasks-from-Ole-in-Supernote and move to Obsidian",
      "path": "P-Tasks/➕/➕--Check-tasks-from-Ole-in-Supernote and move to Obsidian.md"
    },
    {
      "basename": "🧪--PhD-NTNU--Projects--Sleeve-Slip-Problem",
      "path": "NTNU/Org/🧪Projects/Sleeve-Slip--DigiWells/🧪--PhD-NTNU--Projects--Sleeve-Slip-Problem.md"
    },
    {
      "basename": "p477",
      "path": "Literature/Notes/p477.md"
    },
    {
      "basename": "🏨Deep-Mind",
      "path": "NTNU/Org/🧑People/🏨Deep-Mind.md"
    },
    {
      "basename": "LAB",
      "path": "LAB.md"
    },
    {
      "basename": "➕make list of potential places for residency and visualize self",
      "path": "P-Tasks/➕/👨‍🎓/🧪/➕make list of potential places for residency and visualize self.md"
    },
    {
      "basename": "🏨Uni--Melbourne",
      "path": "NTNU/Org/🧑People/🏨Uni--Melbourne.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Stochastic-Gradient-Descent",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Stochastic-Gradient-Descent.md"
    },
    {
      "basename": "🔗--ppt--Meetings",
      "path": "Meetings/🔗--ppt--Meetings.md"
    },
    {
      "basename": "Visualize Science Course ❓",
      "path": "P-Tasks/✔/Visualize Science Course ❓.md"
    },
    {
      "basename": "Contents--datav-tasks",
      "path": "Contents--datav-tasks.md"
    },
    {
      "basename": "p451",
      "path": "Literature/Notes/p451.md"
    },
    {
      "basename": "eq--RL--Vanilla-policy-gradient-expression-with-advantage-function",
      "path": "Literature/Theory/Theory/Reinforcement-Learning/Equations/eq--RL--Vanilla-policy-gradient-expression-with-advantage-function.md"
    },
    {
      "basename": "p220--SGD update with linear function approximation",
      "path": "Literature/Notes/p220--SGD update with linear function approximation.md"
    },
    {
      "basename": "p220--89",
      "path": "Literature/Notes/p220--89.md"
    },
    {
      "basename": "💭 In-favor-of--sigmoid--functions",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--sigmoid--functions.md"
    },
    {
      "basename": "💭 In-favor-of--RL--TRPO",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--TRPO.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Tile-Coding",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Tile-Coding.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Temporal-Difference-Learning",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Temporal-Difference-Learning.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Residual-Algorithms",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Residual-Algorithms.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Residual-Gradients",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Residual-Gradients.md"
    },
    {
      "basename": "💭 In-favor-of--RL--Policy-Gradient 2023-04-23 14_41_10",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--Policy-Gradient 2023-04-23 14_41_10.md"
    },
    {
      "basename": "💭 In-favor-of--Reinforcement-Learning",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--Reinforcement-Learning.md"
    },
    {
      "basename": "💭 In-favor-of--RL--approximating-value-functions",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--RL--approximating-value-functions.md"
    },
    {
      "basename": "💭 In-favor-of--Integral-Adaptive-Law--against-Instantaneous-Adaptive-Law",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--Integral-Adaptive-Law--against-Instantaneous-Adaptive-Law.md"
    },
    {
      "basename": "💭 In-favor-of--Iterative-Learning--Control",
      "path": "Literature/Notes/💭 Arguments/in favor of/💭 In-favor-of--Iterative-Learning--Control.md"
    },
    {
      "basename": "💭 Against--Extremum-Seeking--Perturbation-Based",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--Extremum-Seeking--Perturbation-Based.md"
    },
    {
      "basename": "💭 Against--high-frequency-perturbations",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--high-frequency-perturbations.md"
    },
    {
      "basename": "💭 Against--Extremum-Seeking--Model-Based",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--Extremum-Seeking--Model-Based.md"
    },
    {
      "basename": "💭 Against--Extremum--Seeking",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--Extremum--Seeking.md"
    },
    {
      "basename": "💭 Against--Adaptive-Control-Approaches",
      "path": "Literature/Notes/💭 Arguments/against/💭 Against--Adaptive-Control-Approaches.md"
    },
    {
      "basename": "p220--63",
      "path": "Literature/Notes/p220--63.md"
    },
    {
      "basename": "hour-count--tasks",
      "path": "hour-count--tasks.md"
    },
    {
      "basename": "reimburcement of December 2022 Stavanger trip",
      "path": "P-Tasks/✔/reimburcement of December 2022 Stavanger trip.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}